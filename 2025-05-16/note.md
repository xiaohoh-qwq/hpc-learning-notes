# CMU 15-418 Lecture 2 学习笔记：并行计算的硬件视角

> 本讲核心：从硬件层面理解并行计算，重点介绍 GPU 架构、SIMD/SPMD 模型、缓存机制和多线程调度等。

---

## 一、并行计算的硬件潜力

- 现代计算平台普遍具备多核、多线程、向量化指令支持（如 AVX），甚至包含 GPU。
- **并行性在多个硬件层级上存在**：
  - **透明并行性**：硬件自动处理，如缓存预取、乱序执行；
  - **可编程并行性**：需要程序员显式控制，如 GPU 核心调度、线程划分。

---

## 二、GPU 与并行计算

- **GPU = 大量简单核心 + 高吞吐设计**
  - 适合高并发任务（如图像处理、深度学习）。
- **SPMD（Single Program Multiple Data）**：
  - 所有线程运行同一程序，但处理不同数据。
- 底层使用 **SIMD** 实现逻辑，每个“warp”中线程执行相同指令。

---

## 三、SIMD 架构与指令集

- **SIMD（Single Instruction, Multiple Data）**：
  - 一条指令作用于多个数据，适合数据并行操作。
  - 示例：向量加法、图像滤波。
- **一致性（Coherence） vs 分歧（Divergence）**：
  - SIMD 结构要求线程执行相同操作，分歧将降低效率。
- **AVX 指令集**：
  - 支持向量级字节/整型/浮点计算；
  - AVX2 支持整数操作，AVX-512 扩展寄存器宽度和操作能力。

---

## 四、缓存与延迟隐藏

- **缓存层次结构**（L1/L2/L3）：加速内存访问、降低延迟。
- **预取机制（Prefetching）**：硬件可提前加载数据，提升带宽利用率。
- **延迟隐藏技术**：
  - 多线程（线程间切换）；
  - 指令乱序与预取；
  - 高带宽内存（如 HBM）。

---

## 五、多线程与超线程（Simultaneous Multithreading）

- 一个核心可以同时执行多个线程，减少因等待内存等资源造成的空闲。
- **超线程（SMT）工作原理**：
  - 复制寄存器集合；
  - 共享执行单元与缓存。
- **线程调度责任**：
  - CPU：主要由操作系统调度；
  - GPU：硬件调度（warp-based scheduling）。

---

## 六、并行编程的挑战与模型

- **挑战**：
  - 负载不平衡；
  - 通信延迟；
  - 内存带宽瓶颈；
  - 分支分歧与同步开销。
- **优化目标**：
  - 提高资源利用率；
  - 最小化线程间通信；
  - 隐藏延迟，提高吞吐量。
- **尴尬并行（Embarrassingly Parallel）**：
  - 指任务之间完全独立，无需通信，如图像像素处理、蒙特卡洛模拟。
  - 极其适合并行化和 GPU 加速。

---

## 七、从顺序模型到并行编程

- 传统顺序程序在多核系统上不能充分发挥硬件潜力。
- 使用 **线程模型（OpenMP、Pthreads）** 实现显式并行。
- 编写并行代码需要考虑：
  - 数据划分；
  - 同步与通信；
  - 指令执行路径的差异性。

---

## 八、并行计算的价值与注意事项

- **性能提升**：缩短运行时间，提高吞吐量；
- **功耗优化**：在相同功耗下完成更多任务；
- **并非万金油**：需注意并行成本（线程调度、同步、内存冲突）；
- **内存带宽限制显著**：往往是性能瓶颈，应通过重用数据、压缩表示等技巧缓解。

---

## 总结

- 并行计算不仅是软件设计问题，更深深根植于硬件结构之中；
- 理解 GPU、SIMD、SPMD、多线程与缓存机制，是高效并行程序设计的基础；
- 编程时需平衡“性能提升”与“复杂性增加”的代价，寻找任务与架构的最佳匹配。
