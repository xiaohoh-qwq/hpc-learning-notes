# CMU 15-418 第三讲笔记：并行编程与性能

本讲讨论如何编写高效的并行程序，涵盖并行抽象模型、ISPC语言、共享/消息/数据并行三大主流范式，以及底层实现中的挑战和性能权衡。

---

## 一、并行编程基础

1. 本课程将系统讲授并行软件的编写方法。
2. **抽象与实现的区分非常关键**：
   - 抽象：如 SPMD、共享地址空间等，是程序员使用的思维模型。
   - 实现：可能包括线程调度、内存分配、硬件指令等细节。
   - 注意：不应混淆编程抽象与其底层运行机制。

---

## 二、ISPC 与 SPMD 编程模型

3. **ISPC（Intel SPMD Program Compiler）** 是一种适合数据并行计算的语言，能生成高效的 SIMD 代码。
4. ISPC 采用 **SPMD（Single Program, Multiple Data）** 模型：
   - 多个执行实例运行同一个程序，对应于不同的数据段。
   - 类似于“每个数据点有一个小线程”。
5. ISPC 提供两种数据布局方式：
   - **Interleaved（交错）**：每个程序实例处理间隔访问的数据。
   - **Blocked（阻塞）**：每个实例处理一段连续数据块。

6. 阻塞 vs 交错：
   - Blocked 更适合数据局部性强的场景（如图像处理）。
   - Interleaved 在某些访存模式下避免内存带宽瓶颈。

7. `foreach` 是 ISPC 中的原语结构：
   - 编译器负责将循环并行化，程序员不需手动分配线程。
   - 示例：

     ```c
     export void square(uniform float* a, uniform float* b, uniform int N) {
         foreach (i = 0 ... N) {
             b[i] = a[i] * a[i];
         }
     }
     ```

8. ISPC 提供共享地址空间抽象：
   - 程序实例可以访问公共数组、指针等变量。
   - **程序视角是共享的，但底层实现可在 SIMD 寄存器或显式 load/store。**

---

## 三、共享地址空间模型

9. 实现方式：
   - **物理共享内存**（如常见的多核处理器）
   - **NUMA（Non-Uniform Memory Access）**：
     - 多处理器节点有各自内存。
     - 访问远端内存开销更高。

10. 优点：
    - 通信简洁：直接通过共享变量读写。
    - 编程友好：可重用串行代码结构。

11. 缺点：
    - 存在数据竞争与同步问题。
    - 必须手动添加互斥机制（如锁、屏障等）。

12. 示例说明：
    - 一台有两个 CPU 插槽的服务器，若每个插槽有自己的内存条，那就是 NUMA 系统。

13. 编程模型示意（共享内存）：
    ```text
    线程A ──┐
           ├──→ [ 共享数组 memory[] ]
    线程B ──┘
    ```

---

## 四、消息传递模型

14. 每个线程拥有**私有内存**，通过消息进行通信。
15. 编程范式显式：需要发送消息、接收消息。
16. 常用接口如 **MPI（Message Passing Interface）**。
17. 优点：
    - 数据隔离，线程间无隐式共享，**不会有数据竞争**。
18. 缺点：
    - 通信编程复杂。
    - 延迟与带宽显式成为性能瓶颈。

---

## 五、数据并行与流编程

19. 数据并行：将相同操作同时应用于一组数据。
20. 映射结构：

    ```text
    f(x) = x^2

    数据集： [1, 2, 3, 4]
    并行计算： [f(1), f(2), f(3), f(4)]
    ```

21. 特点：
    - 高吞吐量，适合批处理场景。
    - GPU 编程（CUDA、OpenCL）是其典型应用。

22. 流模型：
    - 数据从一个节点流向另一个节点，每步应用纯函数。
    - 天然支持流水线与无副作用处理。

23. 两者都避免共享数据带来的不确定性问题。

---

## 六、模型比较与实践建议

24. 三种模型通信方式比较：

| 模型类型           | 通信方式         | 是否共享内存 | 适用场景                     |
|--------------------|------------------|---------------|------------------------------|
| 共享地址空间       | 内存读写         | 是            | 多核 CPU、OpenMP             |
| 消息传递           | 显式消息发送     | 否            | 分布式系统、MPI              |
| 数据并行（SIMD）   | 映射函数到数据集 | 否（或间接）  | GPU、大规模批处理            |

25. 实践中：
   - 真正的高性能并行系统常常混合使用三种模型。
   - 例如：
     - 多节点集群：**MPI**
     - 单节点内多核协作：**OpenMP / ISPC**
     - GPU 加速计算：**CUDA / OpenCL**

---

## 七、术语小结

| 名称       | 说明 |
|------------|------|
| ISPC       | Intel SPMD Program Compiler，生成 SIMD 指令的 C 风格语言 |
| SPMD       | 每个程序实例执行相同程序但处理不同数据 |
| NUMA       | 不同内存访问速度的多插槽系统结构 |
| SIMD       | 单指令多数据 |
| Fork-Join  | 并行任务生成与汇合的一种模型 |
| `foreach`  | ISPC 提供的用于 SPMD 并行的原语 |

---

